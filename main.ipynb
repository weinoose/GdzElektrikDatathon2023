{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 — IMPORTING LIBRARIES\n",
    "signed by Emir Yarkın Yaman a.k.a. WEINOOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 — FEATURE ENGINEERING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.1 — data location for forecast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.DataFrame(pd.read_csv('Izmir Hava Durumu 2018-08.31.2023.csv'))\n",
    "totalentry_forecast = len(list(forecast[list(forecast.columns)[0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.2 — deleting %30> NaN filled columns at weather forecast, replacing rest of to NaN values to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = pd.DataFrame(forecast.isna().sum())\n",
    "temp0.rename(columns={0: 'ixx'}, inplace=True)\n",
    "temp0 = temp0.query(f'ixx >= {totalentry_forecast*0.3}')\n",
    "forecast = forecast.drop(columns=temp0.index.to_list(), axis=1).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.3 — copying dataset for seperate time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast00 = forecast.copy(deep=True)\n",
    "forecast01 = forecast.copy(deep=True)\n",
    "forecast02 = forecast.copy(deep=True)\n",
    "forecast03 = forecast.copy(deep=True)\n",
    "forecast04 = forecast.copy(deep=True)\n",
    "forecast05 = forecast.copy(deep=True)\n",
    "forecast06 = forecast.copy(deep=True)\n",
    "forecast07 = forecast.copy(deep=True)\n",
    "forecast08 = forecast.copy(deep=True)\n",
    "forecast09 = forecast.copy(deep=True)\n",
    "forecast10 = forecast.copy(deep=True)\n",
    "forecast11 = forecast.copy(deep=True)\n",
    "forecast12 = forecast.copy(deep=True)\n",
    "forecast13 = forecast.copy(deep=True)\n",
    "forecast14 = forecast.copy(deep=True)\n",
    "forecast15 = forecast.copy(deep=True)\n",
    "forecast16 = forecast.copy(deep=True)\n",
    "forecast17 = forecast.copy(deep=True)\n",
    "forecast18 = forecast.copy(deep=True)\n",
    "forecast19 = forecast.copy(deep=True)\n",
    "forecast20 = forecast.copy(deep=True)\n",
    "forecast21 = forecast.copy(deep=True)\n",
    "forecast22 = forecast.copy(deep=True)\n",
    "forecast23 = forecast.copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.4 — adding timeseries weight for weather forecast by 24-hour basis for one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_of_days, templist = [], forecast['date'].to_list()\n",
    "for i in range(0,24):\n",
    "    hours_of_days.append([])\n",
    "\n",
    "for i in templist:\n",
    "    var_date = i\n",
    "    for q in range(0,24):\n",
    "        if q < 10:\n",
    "            var_date_new = f'{var_date} 0{q}:00:00'\n",
    "        else:\n",
    "            var_date_new = f'{var_date} {q}:00:00'\n",
    "        hours_of_days[q].append(var_date_new)\n",
    "\n",
    "forecast00['date'] = hours_of_days[0]\n",
    "forecast01['date'] = hours_of_days[1]\n",
    "forecast02['date'] = hours_of_days[2]\n",
    "forecast03['date'] = hours_of_days[3]\n",
    "forecast04['date'] = hours_of_days[4]\n",
    "forecast05['date'] = hours_of_days[5]\n",
    "forecast06['date'] = hours_of_days[6]\n",
    "forecast07['date'] = hours_of_days[7]\n",
    "forecast08['date'] = hours_of_days[8]\n",
    "forecast09['date'] = hours_of_days[9]\n",
    "forecast10['date'] = hours_of_days[10]\n",
    "forecast11['date'] = hours_of_days[11]\n",
    "forecast12['date'] = hours_of_days[12]\n",
    "forecast13['date'] = hours_of_days[13]\n",
    "forecast14['date'] = hours_of_days[14]\n",
    "forecast15['date'] = hours_of_days[15]\n",
    "forecast16['date'] = hours_of_days[16]\n",
    "forecast17['date'] = hours_of_days[17]\n",
    "forecast18['date'] = hours_of_days[18]\n",
    "forecast19['date'] = hours_of_days[19]\n",
    "forecast20['date'] = hours_of_days[20]\n",
    "forecast21['date'] = hours_of_days[21]\n",
    "forecast22['date'] = hours_of_days[22]\n",
    "forecast23['date'] = hours_of_days[23]\n",
    "\n",
    "forecast_data = pd.concat([forecast00,forecast01,forecast02,forecast03,forecast04,forecast05,\n",
    "                           forecast06,forecast07,forecast08,forecast09,forecast10,forecast11,\n",
    "                           forecast12,forecast13,forecast14,forecast15,forecast16,forecast17,\n",
    "                           forecast18,forecast19,forecast20,forecast21,forecast22,forecast23], ignore_index=True, axis=0)\n",
    "\n",
    "forecast_data.rename(columns={'date': 'Tarih'}, inplace=True)\n",
    "\n",
    "forecast_data = forecast_data.sort_values('Tarih', ascending=True)\n",
    "forecast_data = forecast_data.reset_index()\n",
    "forecast_data = forecast_data.drop(columns=['index'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.0 — merging datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(pd.read_csv('train.csv'))\n",
    "test_dates = pd.DataFrame(pd.read_csv('sample_submission.csv'))\n",
    "august = forecast_data.drop(labels=range(0, 40152), axis=0)\n",
    "\n",
    "data = pd.concat([train_data.merge(forecast_data, on='Tarih', how='inner'), \n",
    "                  test_dates.merge(august, on='Tarih', how='inner')], \n",
    "                  ignore_index=True, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.0 — identifying power outages with the help of 'med.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "outage, new_med_data = [], []\n",
    "med_data = pd.DataFrame(pd.read_csv('med.csv'))['Tarih'].to_list()\n",
    "\n",
    "for var_date in med_data:\n",
    "    var_date = str(var_date.replace('.','-')).split('-')\n",
    "    if int(var_date[0]) < 10:\n",
    "        var_date = f'{var_date[2]}-{var_date[1]}-0{var_date[0]}'\n",
    "    else:\n",
    "        var_date = f'{var_date[2]}-{var_date[1]}-{var_date[0]}'\n",
    "    for hour in range(0,24):\n",
    "        if hour < 10:\n",
    "            var = f'{var_date} 0{hour}:00:00'\n",
    "        else:\n",
    "            var = f'{var_date} {hour}:00:00'\n",
    "        new_med_data.append(var)\n",
    "new_med_data.sort()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 — creating a binary column about power outage, and adding them to both test and train datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Tarih'].to_list():\n",
    "    if i in new_med_data:\n",
    "        outage.append(1)\n",
    "    else:\n",
    "        outage.append(0)\n",
    "\n",
    "data['Power Outage (MED)'] = outage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.0 — now adding extra weights like; weekin, weekend. / day of the year. / week of the year. / morning, afternoon, evening, night... also 01.01.2018 is monday so we are good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = preprocessing.LabelEncoder().fit_transform(data['Tarih'])\n",
    "hours = []\n",
    "\n",
    "day_status = []\n",
    "weekends = []\n",
    "day_of_the_year = []\n",
    "week_of_the_year = []\n",
    "\n",
    "for i in data['Tarih'].to_list():\n",
    "    hours.append(int(i[11:13]))\n",
    "\n",
    "for hour in hours:\n",
    "    if 10 >= hour >= 6:\n",
    "        day_status.append('sabah')\n",
    "    elif 16 >= hour >= 11:\n",
    "        day_status.append('öğlen')\n",
    "    elif 21 >= hour >= 17:\n",
    "        day_status.append('akşam')\n",
    "    else:\n",
    "        day_status.append('gece')\n",
    "\n",
    "for day in dates:\n",
    "    # weekend finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    day_of_the_week = the_date.weekday()\n",
    "    if day_of_the_week == 5 or day_of_the_week == 6:\n",
    "        weekends.append(1)\n",
    "    else:\n",
    "        weekends.append(0)\n",
    "\n",
    "for day in dates:\n",
    "    # day of the year finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    day_of_the_year.append(the_date.timetuple().tm_yday)\n",
    "\n",
    "for day in dates:\n",
    "    # week of the year finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    week_of_the_year.append(the_date.isocalendar()[1])\n",
    "\n",
    "# label encoding the day status to convert string values to numerical features.\n",
    "day_status = preprocessing.LabelEncoder().fit_transform(day_status)\n",
    "\n",
    "# let's convert date column into seperate columns.\n",
    "day, month, year, hourrr = [], [], [], []\n",
    "for i in data['Tarih'].to_list():\n",
    "    year.append(int(i[0:4]))\n",
    "    month.append(int(i[5:7]))\n",
    "    day.append(int(i[8:10]))\n",
    "    hourrr.append(int(i[11:13]))\n",
    "data = data.drop(columns=['Tarih'],axis=1)\n",
    "\n",
    "# finalizing the assignments.\n",
    "data['Günün Vakti'] = day_status\n",
    "data['Yılın Günü'] = day_of_the_year\n",
    "data['Yılın Haftası'] = week_of_the_year\n",
    "data['Haftasonu'] = weekends\n",
    "data['Yıl'] = year\n",
    "data['Ay'] = month\n",
    "data['Gün'] = day\n",
    "data['Saat'] = hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 — DATA TRAIN (TRAIN & TEST SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "submission = data.drop(labels=range(0, 40152), axis=0)\n",
    "\n",
    "data = data.drop(labels=range(40152, 40896), axis=0)\n",
    "y = data['Dağıtılan Enerji (MWh)'].values\n",
    "\n",
    "data = data.drop(columns=['Dağıtılan Enerji (MWh)'], axis = 1)\n",
    "x = data.values\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 — FEATURE PRE-PROCESSING / NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessing.normalize(x_train)\n",
    "x_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 — GATHERING TRAIN RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "model = XGBRegressor(learning_rate=0.5\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "\n",
    "print(f'R2 Score: {r2_score(y_test,y_predicted)}')\n",
    "print(f'MAPE: {mean_absolute_percentage_error(y_test,y_predicted)}')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(f'5-fold Cross Validation: %{round(cross_val_score(estimator = model, X = x_train, y = y_train, cv = 5).mean()*100,3)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 — MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so as you see above, our feed-backs are good, so let's move forward.\n",
    "x_train = x\n",
    "y_train = y\n",
    "\n",
    "y_test = submission['Dağıtılan Enerji (MWh)'].values\n",
    "submission = submission.drop(columns=['Dağıtılan Enerji (MWh)'], axis=1)\n",
    "\n",
    "x_test = submission.values\n",
    "\n",
    "# normalizing again.\n",
    "x_train = preprocessing.normalize(x_train)\n",
    "x_test = preprocessing.normalize(x_test)\n",
    "\n",
    "# it is time to finalize things.\n",
    "model.fit(x_train, y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "\n",
    "# let's save it into the submission0.csv\n",
    "final, sample_submission = pd.DataFrame(), pd.DataFrame(pd.read_csv('sample_submission.csv'))\n",
    "final['Tarih'] = sample_submission['Tarih']\n",
    "final['Dağıtılan Enerji (MWh)'] = y_predicted\n",
    "\n",
    "# final.to_csv(\"submission3.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
