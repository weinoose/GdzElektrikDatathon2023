{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 — IMPORTING LIBRARIES\n",
    "signed by Emir Yarkın Yaman a.k.a. WEINOOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 — FEATURE ENGINEERING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.1 — data location for forecast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.DataFrame(pd.read_csv('Izmir Hava Durumu 2018-08.31.2023.csv'))\n",
    "totalentry_forecast = len(list(forecast[list(forecast.columns)[0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.2 — deleting %30> NaN filled columns at weather forecast, replacing rest of to NaN values to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = pd.DataFrame(forecast.isna().sum())\n",
    "temp0.rename(columns={0: 'ixx'}, inplace=True)\n",
    "temp0 = temp0.query(f'ixx >= {totalentry_forecast*0.3}')\n",
    "forecast = forecast.drop(columns=temp0.index.to_list(), axis=1).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.3 — copying dataset for seperate time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast00 = forecast.copy(deep=True)\n",
    "forecast01 = forecast.copy(deep=True)\n",
    "forecast02 = forecast.copy(deep=True)\n",
    "forecast03 = forecast.copy(deep=True)\n",
    "forecast04 = forecast.copy(deep=True)\n",
    "forecast05 = forecast.copy(deep=True)\n",
    "forecast06 = forecast.copy(deep=True)\n",
    "forecast07 = forecast.copy(deep=True)\n",
    "forecast08 = forecast.copy(deep=True)\n",
    "forecast09 = forecast.copy(deep=True)\n",
    "forecast10 = forecast.copy(deep=True)\n",
    "forecast11 = forecast.copy(deep=True)\n",
    "forecast12 = forecast.copy(deep=True)\n",
    "forecast13 = forecast.copy(deep=True)\n",
    "forecast14 = forecast.copy(deep=True)\n",
    "forecast15 = forecast.copy(deep=True)\n",
    "forecast16 = forecast.copy(deep=True)\n",
    "forecast17 = forecast.copy(deep=True)\n",
    "forecast18 = forecast.copy(deep=True)\n",
    "forecast19 = forecast.copy(deep=True)\n",
    "forecast20 = forecast.copy(deep=True)\n",
    "forecast21 = forecast.copy(deep=True)\n",
    "forecast22 = forecast.copy(deep=True)\n",
    "forecast23 = forecast.copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.0.4 — adding timeseries weight for weather forecast by 24-hour basis for one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_of_days, templist = [], forecast['date'].to_list()\n",
    "for i in range(0,24):\n",
    "    hours_of_days.append([])\n",
    "\n",
    "for i in templist:\n",
    "    var_date = i\n",
    "    for q in range(0,24):\n",
    "        if q < 10:\n",
    "            var_date_new = f'{var_date} 0{q}:00:00'\n",
    "        else:\n",
    "            var_date_new = f'{var_date} {q}:00:00'\n",
    "        hours_of_days[q].append(var_date_new)\n",
    "\n",
    "forecast00['date'] = hours_of_days[0]\n",
    "forecast01['date'] = hours_of_days[1]\n",
    "forecast02['date'] = hours_of_days[2]\n",
    "forecast03['date'] = hours_of_days[3]\n",
    "forecast04['date'] = hours_of_days[4]\n",
    "forecast05['date'] = hours_of_days[5]\n",
    "forecast06['date'] = hours_of_days[6]\n",
    "forecast07['date'] = hours_of_days[7]\n",
    "forecast08['date'] = hours_of_days[8]\n",
    "forecast09['date'] = hours_of_days[9]\n",
    "forecast10['date'] = hours_of_days[10]\n",
    "forecast11['date'] = hours_of_days[11]\n",
    "forecast12['date'] = hours_of_days[12]\n",
    "forecast13['date'] = hours_of_days[13]\n",
    "forecast14['date'] = hours_of_days[14]\n",
    "forecast15['date'] = hours_of_days[15]\n",
    "forecast16['date'] = hours_of_days[16]\n",
    "forecast17['date'] = hours_of_days[17]\n",
    "forecast18['date'] = hours_of_days[18]\n",
    "forecast19['date'] = hours_of_days[19]\n",
    "forecast20['date'] = hours_of_days[20]\n",
    "forecast21['date'] = hours_of_days[21]\n",
    "forecast22['date'] = hours_of_days[22]\n",
    "forecast23['date'] = hours_of_days[23]\n",
    "\n",
    "forecast_data = pd.concat([forecast00,forecast01,forecast02,forecast03,forecast04,forecast05,\n",
    "                           forecast06,forecast07,forecast08,forecast09,forecast10,forecast11,\n",
    "                           forecast12,forecast13,forecast14,forecast15,forecast16,forecast17,\n",
    "                           forecast18,forecast19,forecast20,forecast21,forecast22,forecast23], ignore_index=True, axis=0)\n",
    "\n",
    "forecast_data.rename(columns={'date': 'Tarih'}, inplace=True)\n",
    "\n",
    "forecast_data = forecast_data.sort_values('Tarih', ascending=True)\n",
    "forecast_data = forecast_data.reset_index()\n",
    "forecast_data = forecast_data.drop(columns=['index'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.0 — merging datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(pd.read_csv('train.csv'))\n",
    "test_dates = pd.DataFrame(pd.read_csv('sample_submission.csv'))\n",
    "august = forecast_data.drop(labels=range(0, 40152), axis=0)\n",
    "\n",
    "data = pd.concat([train_data.merge(forecast_data, on='Tarih', how='inner'), \n",
    "                  test_dates.merge(august, on='Tarih', how='inner')], \n",
    "                  ignore_index=True, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.0 — identifying power outages with the help of 'med.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outage, new_med_data = [], []\n",
    "med_data = pd.DataFrame(pd.read_csv('med.csv'))['Tarih'].to_list()\n",
    "\n",
    "for var_date in med_data:\n",
    "    var_date = str(var_date.replace('.','-')).split('-')\n",
    "    if int(var_date[0]) < 10:\n",
    "        var_date = f'{var_date[2]}-{var_date[1]}-0{var_date[0]}'\n",
    "    else:\n",
    "        var_date = f'{var_date[2]}-{var_date[1]}-{var_date[0]}'\n",
    "    for hour in range(0,24):\n",
    "        if hour < 10:\n",
    "            var = f'{var_date} 0{hour}:00:00'\n",
    "        else:\n",
    "            var = f'{var_date} {hour}:00:00'\n",
    "        new_med_data.append(var)\n",
    "new_med_data.sort()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 — creating a binary column about power outage, and adding them to both test and train datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Tarih'].to_list():\n",
    "    if i in new_med_data:\n",
    "        outage.append(1)\n",
    "    else:\n",
    "        outage.append(0)\n",
    "\n",
    "data['Majör Elektrik Kesintisi'] = outage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.0 — now adding extra weights like; weekin, weekend. / day of the year. / week of the year. / morning, afternoon, evening, night... also 01.01.2018 is monday so we are good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = preprocessing.LabelEncoder().fit_transform(data['Tarih'])\n",
    "hours = []\n",
    "\n",
    "day_status = []\n",
    "weekends = []\n",
    "day_of_the_year = []\n",
    "week_of_the_year = []\n",
    "\n",
    "for i in data['Tarih'].to_list():\n",
    "    hours.append(int(i[11:13]))\n",
    "\n",
    "for hour in hours:\n",
    "    if 10 >= hour >= 6:\n",
    "        day_status.append('sabah')\n",
    "    elif 16 >= hour >= 11:\n",
    "        day_status.append('öğlen')\n",
    "    elif 21 >= hour >= 17:\n",
    "        day_status.append('akşam')\n",
    "    else:\n",
    "        day_status.append('gece')\n",
    "\n",
    "for day in dates:\n",
    "    # weekend finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    day_of_the_week = the_date.weekday()\n",
    "    if day_of_the_week == 5 or day_of_the_week == 6:\n",
    "        weekends.append(1)\n",
    "    else:\n",
    "        weekends.append(0)\n",
    "\n",
    "for day in dates:\n",
    "    # day of the year finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    day_of_the_year.append(the_date.timetuple().tm_yday)\n",
    "\n",
    "for day in dates:\n",
    "    # week of the year finder.\n",
    "    the_date = datetime.date(2018, 1, 1) + datetime.timedelta(days=int(day))\n",
    "    week_of_the_year.append(the_date.isocalendar()[1])\n",
    "\n",
    "# label encoding the day status to convert string values to numerical features.\n",
    "day_status = preprocessing.LabelEncoder().fit_transform(day_status)\n",
    "\n",
    "# let's convert date column into seperate columns.\n",
    "day, month, year, hourrr = [], [], [], []\n",
    "for i in data['Tarih'].to_list():\n",
    "    year.append(int(i[0:4]))\n",
    "    month.append(int(i[5:7]))\n",
    "    day.append(int(i[8:10]))\n",
    "    hourrr.append(int(i[11:13]))\n",
    "data = data.drop(columns=['Tarih'],axis=1)\n",
    "\n",
    "# finalizing the assignments volume-1.\n",
    "data['Günün Vakti'] = day_status\n",
    "data['Yılın Günü'] = day_of_the_year\n",
    "data['Yılın Haftası'] = week_of_the_year\n",
    "data['Haftasonu'] = weekends\n",
    "data['Yıl'] = year\n",
    "data['Ay'] = month\n",
    "data['Gün'] = day\n",
    "data['Saat'] = hour\n",
    "\n",
    "# adding more extra weights. / official holidays.\n",
    "official_holidays = ['2018-1-1','2018-4-23','2018-5-1','2018-5-19','2018-8-30','2018-10-28',\n",
    "                     '2018-10-29','2018-7-15','2018-6-14','2018-6-15','2018-6-16','2018-6-17',\n",
    "                     '2018-8-20','2018-8-21','2018-8-22','2018-8-23','2018-8-24','2019-1-1',\n",
    "                     '2019-4-23','2019-5-1','2019-5-19','2019-8-30','2019-10-28','2019-10-29',\n",
    "                     '2019-7-15','2019-6-4','2019-6-5','2019-6-6','2019-6-7','2019-8-10',\n",
    "                     '2019-8-11','2019-8-12','2019-8-13','2019-8-14','2020-1-1','2020-4-23',\n",
    "                     '2020-5-1','2020-5-19','2020-8-30','2020-10-28','2020-10-29','2020-7-15',\n",
    "                     '2020-5-23','2020-5-24','2020-5-25','2020-5-26','2020-7-30','2020-7-31',\n",
    "                     '2020-8-1','2020-8-2','2020-8-3','2021-1-1','2021-4-23','2021-5-1',\n",
    "                     '2021-5-19','2021-8-30','2021-10-28','2021-10-29','2021-7-15','2021-5-12',\n",
    "                     '2021-5-13','2021-5-14','2021-5-15','2021-7-19','2021-7-20','2021-7-21',\n",
    "                     '2021-7-22','2021-7-23','2022-1-1','2022-4-23','2022-5-1','2022-5-19',\n",
    "                     '2022-8-30','2022-10-28','2022-10-29','2022-7-15','2022-5-2','2022-5-3',\n",
    "                     '2022-5-4','2022-7-8','2022-7-9','2022-7-10','2022-7-11','2022-7-12']\n",
    "numeric_holidays = []\n",
    "\n",
    "for r,m,n in zip(list(data['Yıl']),list(data['Ay']),list(data['Gün'])):\n",
    "    hol = str(f'{r}-{m}-{n}')\n",
    "    if hol in official_holidays:\n",
    "        numeric_holidays.append(1)\n",
    "    else:\n",
    "        numeric_holidays.append(0)\n",
    "\n",
    "data['Resmi Tatil_temp'] = numeric_holidays\n",
    "\n",
    "# adding more extra weights. / ramadan holiday.\n",
    "ramadan_holidays = ['2018-5-16','2018-5-17','2018-5-18','2018-5-19','2018-5-20','2018-5-21','2018-5-22','2018-5-23','2018-5-24',\n",
    "                    '2018-5-25','2018-5-26','2018-5-27','2018-5-28','2018-5-29','2018-5-30','2018-5-31','2018-6-1','2018-6-2',\n",
    "                    '2018-6-3','2018-6-4','2018-6-5','2018-6-6','2018-6-7','2018-6-8','2018-6-9','2018-6-10','2018-6-11',\n",
    "                    '2018-6-12','2018-6-13','2018-6-14',\n",
    "                    \n",
    "                    '2019-5-6','2019-5-7','2019-5-8','2019-5-9','2019-5-10','2019-5-11','2019-5-12','2019-5-13','2019-5-14',\n",
    "                    '2019-5-15','2019-5-16','2019-5-17','2019-5-18','2019-5-19','2019-5-20','2019-5-21','2019-5-22','2019-5-23',\n",
    "                    '2019-5-24','2019-5-25','2019-5-26','2019-5-27','2019-5-28','2019-5-29','2019-5-30','2019-5-31','2019-6-1',\n",
    "                    '2019-6-2','2019-6-3',\n",
    "                    \n",
    "                    '2020-4-24','2020-4-25','2020-4-26','2020-4-27','2020-4-28','2020-4-29','2020-4-30','2020-5-1','2020-5-2',\n",
    "                    '2020-5-3','2020-5-4','2020-5-5','2020-5-6','2020-5-7','2020-5-8','2020-5-9','2020-5-10','2020-5-11',\n",
    "                    '2020-5-12','2020-5-13','2020-5-14','2020-5-15','2020-5-16','2020-5-17','2020-5-18','2020-5-19','2020-5-20',\n",
    "                    '2020-5-21','2020-5-22','2020-5-23',\n",
    "                    \n",
    "                    '2021-4-13','2021-4-14','2021-4-15','2021-4-16','2021-4-17','2021-4-18','2021-4-19','2021-4-20','2021-4-21',\n",
    "                    '2021-4-22','2021-4-23','2021-4-24','2021-4-25','2021-4-26','2021-4-27','2021-4-28','2021-4-29','2021-4-30',\n",
    "                    '2021-5-1','2021-5-2','2021-5-3','2021-5-4','2021-5-5','2021-5-6','2021-5-7','2021-5-8','2021-5-9',\n",
    "                    '2021-5-10','2021-5-11','2021-5-12',\n",
    "                    \n",
    "                    '2022-4-2','2022-4-3','2022-4-4','2022-4-5','2022-4-6','2022-4-7','2022-4-8','2022-4-9','2022-4-10',\n",
    "                    '2022-4-11','2022-4-12','2022-4-13','2022-4-14','2022-4-15','2022-4-16','2022-4-17','2022-4-18','2022-4-19',\n",
    "                    '2022-4-20','2022-4-21','2022-4-22','2022-4-23','2022-4-24','2022-4-25','2022-4-26','2022-4-27','2022-4-28',\n",
    "                    '2022-4-29','2022-4-30','2022-5-1']\n",
    "\n",
    "numeric_ramadan = []\n",
    "\n",
    "for c,v,b in zip(list(data['Yıl']),list(data['Ay']),list(data['Gün'])):\n",
    "    rhol = str(f'{c}-{v}-{b}')\n",
    "    if rhol in ramadan_holidays:\n",
    "        numeric_ramadan.append(1)\n",
    "    else:\n",
    "        numeric_ramadan.append(0)\n",
    "\n",
    "data['Ramazan_temp'] = numeric_ramadan\n",
    "\n",
    "# adding seasons.\n",
    "seasons = []\n",
    "for i in data['Ay'].to_list():\n",
    "    if 5 >= i >= 3:\n",
    "        seasons.append(1)\n",
    "    elif 8 >= i >= 6:\n",
    "        seasons.append(2)\n",
    "    elif 11 >= i >= 9:\n",
    "        seasons.append(3)\n",
    "    else:\n",
    "        seasons.append(0)\n",
    "\n",
    "data['Mevsim'] = seasons\n",
    "\n",
    "# handling cyclical data.\n",
    "data['sin(Günün Vakti)'] = np.sin((2*np.pi*data['Günün Vakti'])/data['Günün Vakti'].max())\n",
    "data['cos(Günün Vakti)'] = np.cos((2*np.pi*data['Günün Vakti'])/data['Günün Vakti'].max())\n",
    "data = data.drop(columns=['Günün Vakti'], axis=1)\n",
    "\n",
    "data['sin(Yılın Günü)'] = np.sin((2*np.pi*data['Yılın Günü'])/data['Yılın Günü'].max())\n",
    "data['cos(Yılın Günü)'] = np.cos((2*np.pi*data['Yılın Günü'])/data['Yılın Günü'].max())\n",
    "data = data.drop(columns=['Yılın Günü'], axis=1)\n",
    "\n",
    "data['sin(Yılın Haftası)'] = np.sin((2*np.pi*data['Yılın Haftası'])/data['Yılın Haftası'].max())\n",
    "data['cos(Yılın Haftası)'] = np.cos((2*np.pi*data['Yılın Haftası'])/data['Yılın Haftası'].max())\n",
    "data = data.drop(columns=['Yılın Haftası'], axis=1)\n",
    "\n",
    "data['sin(Saat)'] = np.sin((2*np.pi*data['Saat'])/data['Saat'].max())\n",
    "data['cos(Saat)'] = np.cos((2*np.pi*data['Saat'])/data['Saat'].max())\n",
    "data = data.drop(columns=['Saat'], axis=1)\n",
    "\n",
    "data['sin(Gün)'] = np.sin((2*np.pi*data['Gün'])/data['Gün'].max())\n",
    "data['cos(Gün)'] = np.cos((2*np.pi*data['Gün'])/data['Gün'].max())\n",
    "data = data.drop(columns=['Gün'], axis=1)\n",
    "\n",
    "\n",
    "data['sin(Ay)'] = np.sin((2*np.pi*data['Ay'])/data['Ay'].max())\n",
    "data['cos(Ay)'] = np.cos((2*np.pi*data['Ay'])/data['Ay'].max())\n",
    "data = data.drop(columns=['Ay'], axis=1)\n",
    "\n",
    "data['sin(Mevsim)'] = np.sin((2*np.pi*data['Mevsim'])/data['Mevsim'].max())\n",
    "data['cos(Mevsim)'] = np.cos((2*np.pi*data['Mevsim'])/data['Mevsim'].max())\n",
    "data = data.drop(columns=['Mevsim'], axis=1)\n",
    "\n",
    "# some placement corrections.\n",
    "data['Resmi Tatil'] = data['Resmi Tatil_temp'].values\n",
    "data['Ramazan'] = data['Ramazan_temp'].values\n",
    "\n",
    "data = data.drop(columns=['Resmi Tatil_temp'], axis=1)\n",
    "data = data.drop(columns=['Ramazan_temp'], axis=1)\n",
    "\n",
    "# label encoding on year feature.\n",
    "data['Yıl'] = preprocessing.LabelEncoder().fit_transform(data['Yıl'])\n",
    "\n",
    "# handling weather forecast data again.\n",
    "data = data.drop(columns=['prcp'],axis=1)\n",
    "\n",
    "#\n",
    "data['Dağıtılan Enerji (MWh)'] = (data['Dağıtılan Enerji (MWh)'])*(36*(10**5))\n",
    "data.rename(columns = {'Dağıtılan Enerji (MWh)':'Dağıtılan Enerji (Joule)'}, inplace = True)\n",
    "\n",
    "# finalizing.\n",
    "data = data\n",
    "TEST = data.drop(labels=range(0, 40152), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 — TRAIN & TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = data.drop(labels=range(40152, 40896), axis=0)\n",
    "y = data['Dağıtılan Enerji (Joule)'].values\n",
    "\n",
    "data = data.drop(columns=['Dağıtılan Enerji (Joule)'], axis = 1)\n",
    "x = data.values\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.02, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 — FEATURE PRE-PROCESSING / NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_on_off = 'off'\n",
    "if normalize_on_off == 'on':\n",
    "    x_train = preprocessing.normalize(x_train)\n",
    "    x_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 — REGULARIZATION / GATHERING TRAIN RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "xgb_optimization_results = {}\n",
    "\n",
    "def xgb_optimization(start,stop,step):\n",
    "    \n",
    "    test_error_list = []\n",
    "    test_mape_list = []\n",
    "    eta_list = []\n",
    "\n",
    "    for c in np.arange(start,stop,step):\n",
    "        \n",
    "        # ,objective='reg:squarederror',reg_alpha=57.0,reg_lambda=0.9,gamma=4.2,max_depth=17,booster='gbtree'\n",
    "        MODEL = XGBRegressor(n_estimators=10000,eta=c,eval_metric='mape')\n",
    "        \n",
    "        MODEL.fit(x_train,y_train) \n",
    "        y_pred = MODEL.predict(x_test)\n",
    "\n",
    "        test_error_list.append((1.0) - (r2_score(y_test,y_pred)))\n",
    "        test_mape_list.append(mean_absolute_percentage_error(y_test,y_pred))\n",
    "        \n",
    "        eta_list.append(c)\n",
    "\n",
    "    xgb_optimization_results['XGB Regressor'] = [eta_list[test_error_list.index(min(test_error_list))],min(test_error_list)]\n",
    "\n",
    "    plt.figure(figsize=(16,10),dpi=80)\n",
    "    plt.grid()\n",
    "    plt.title(f'XGB Regressor\\nBest Learning Rate: {eta_list[test_error_list.index(min(test_error_list))]}\\nMinimum Error Rate: {min(test_error_list)}\\nMinimum MAPE: {test_mape_list[test_error_list.index(min(test_error_list))]}')\n",
    "    plt.plot(eta_list, test_error_list, label='Test Accuracy',c = 'blue',linestyle='dashdot')\n",
    "    plt.plot(eta_list, test_mape_list, label='MAPE',c = 'red',linestyle='dashdot')\n",
    "    plt.ylabel('accuracy rate')\n",
    "    plt.xlabel(\"regularization parameter\")\n",
    "\n",
    "# xgb_optimization(0.005,1.005,0.045)\n",
    "# MODEL = XGBRegressor(n_estimators=10000,eta=xgb_optimization_results['XGB Regressor'][0],eval_metric='mape')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "MODEL = RandomForestRegressor(n_estimators=170,criterion='absolute_error',random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 — MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train values.\n",
    "x_train = x\n",
    "y_train = y\n",
    "\n",
    "# test values. (not seen by the machine learning model yet.)\n",
    "y_test = TEST['Dağıtılan Enerji (Joule)'].values\n",
    "TEST = TEST.drop(columns=['Dağıtılan Enerji (Joule)'], axis=1)\n",
    "x_test = TEST.values\n",
    "\n",
    "if normalize_on_off == 'on':\n",
    "    x_train = preprocessing.normalize(x_train)\n",
    "    x_test = preprocessing.normalize(x_test)\n",
    "\n",
    "# final.\n",
    "MODEL.fit(x_train, y_train)\n",
    "y_predicted = MODEL.predict(x_test)\n",
    "\n",
    "# saving into the submission.\n",
    "final, sample_submission = pd.DataFrame(), pd.DataFrame(pd.read_csv('sample_submission.csv'))\n",
    "final['Tarih'] = sample_submission['Tarih']\n",
    "final['Dağıtılan Enerji (Joule)'] = y_predicted\n",
    "\n",
    "final['Dağıtılan Enerji (Joule)'] = (final['Dağıtılan Enerji (Joule)'])/(36*(10**5))\n",
    "final.rename(columns = {'Dağıtılan Enerji (Joule)':'Dağıtılan Enerji (MWh)'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"finalsubmissionrevisedrandomforest.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
